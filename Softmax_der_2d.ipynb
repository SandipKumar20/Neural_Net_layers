{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(S:ndarray)->ndarray:\n",
    "    return np.exp(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below computes the Softmax function for a 2d tensor input.\n",
    "def Softm_2d(W:ndarray)->ndarray:\n",
    "    assert len(W.shape) == 2  # checking whether W is a 2d tensor.\n",
    "    \n",
    "    Z = np.zeros([W.shape[0],W.shape[1]])  # Initializing the tensor variable to store the output.\n",
    "    n = np.sum(exp(W))\n",
    "    for s in range(W.shape[0]):\n",
    "        for h in range(W.shape[1]):\n",
    "            Z[s,h] = exp(W[s,h])\n",
    "            \n",
    "    return Z/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[5],[3],[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84379473],\n",
       "       [0.1141952 ],\n",
       "       [0.04201007]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Softm_2d(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Softm_1d(w:ndarray)->ndarray:\n",
    "    assert w.ndim == 1 # asserting whether w is a one dimensional tensor.\n",
    "    \n",
    "    z = np.zeros(w.shape[0])\n",
    "    k = np.sum(exp(w))\n",
    "                                   # computing the softmax function for a one d tensor.\n",
    "    for s in range(len(w)):\n",
    "        z[s] = exp(w[s])/k\n",
    "        \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([5,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84379473, 0.1141952 , 0.04201007])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Softm_1d(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.array([[5,2],[4,6],[8,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04120097, 0.00205128],\n",
       "       [0.01515699, 0.11199585],\n",
       "       [0.82754363, 0.00205128]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Softm_2d(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Softm_2d(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Softm_2d_S_2(w:ndarray)->ndarray:\n",
    "    assert w.ndim == 2\n",
    "    W = w.reshape(w.shape[0]*w.shape[1])  # this codelines reshape the 2d tensor to 1d.\n",
    "                                                   \n",
    "                                                      # This function computes the softmax function for 2d tensor variable\n",
    "    S = Softm_1d(W)                                 # using the one dimensional version of softmax.\n",
    "    S_2d = S.reshape(w.shape[0],w.shape[1])            \n",
    "    return S_2d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [3],\n",
       "       [2]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84379473],\n",
       "       [0.1141952 ],\n",
       "       [0.04201007]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Softm_2d_S_2(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Soft_3d(L:ndarray)->ndarray:\n",
    "    assert len(L.shape) == 3\n",
    "    \n",
    "    Z = np.zeros([L.shape[0],L.shape[1],L.shape[2]])       # 3 dimensional version of the softmax function.\n",
    "    \n",
    "    k = np.sum(exp(L))                               # Computing the softmax function for a 2d tensor input.\n",
    "    for s in range(L.shape[0]):\n",
    "        for w in range(L.shape[1]):\n",
    "            for h in range(L.shape[2]):\n",
    "                Z[s,w,h] = exp(L[s,w,h])/(k)\n",
    "                \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [3],\n",
       "       [2]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_3d = w.reshape(w.shape[0],w.shape[1],1)  # w_3d, 3d tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.84379473]],\n",
       "\n",
       "       [[0.1141952 ]],\n",
       "\n",
       "       [[0.04201007]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Soft_3d(w_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function computes softmax function for a 3d tensor using the one dimensional version.\n",
    "def Soft_3d_s_2(L:ndarray)->ndarray:\n",
    "    assert L.ndim == 3\n",
    "    \n",
    "    l = L.reshape(L.shape[0]*L.shape[1]*L.shape[2])  # reshaping the 3d tensor into 1d tensor.\n",
    "    \n",
    "    s = Softm_1d(l)\n",
    "    \n",
    "    return s.reshape(L.shape[0],L.shape[1],L.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.84379473]],\n",
       "\n",
       "       [[0.1141952 ]],\n",
       "\n",
       "       [[0.04201007]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Soft_3d_s_2(w_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.random.randint(2,9,size=(3,2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4, 5, 5, 2],\n",
       "        [2, 4, 7, 5]],\n",
       "\n",
       "       [[7, 8, 6, 3],\n",
       "        [7, 7, 7, 5]],\n",
       "\n",
       "       [[5, 7, 5, 6],\n",
       "        [4, 4, 7, 4]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00431177, 0.01172061, 0.01172061, 0.00058353],\n",
       "        [0.00058353, 0.00431177, 0.08660424, 0.01172061]],\n",
       "\n",
       "       [[0.08660424, 0.23541472, 0.03185992, 0.00158621],\n",
       "        [0.08660424, 0.08660424, 0.08660424, 0.01172061]],\n",
       "\n",
       "       [[0.01172061, 0.08660424, 0.01172061, 0.03185992],\n",
       "        [0.00431177, 0.00431177, 0.08660424, 0.00431177]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Soft_3d(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00431177, 0.01172061, 0.01172061, 0.00058353],\n",
       "        [0.00058353, 0.00431177, 0.08660424, 0.01172061]],\n",
       "\n",
       "       [[0.08660424, 0.23541472, 0.03185992, 0.00158621],\n",
       "        [0.08660424, 0.08660424, 0.08660424, 0.01172061]],\n",
       "\n",
       "       [[0.01172061, 0.08660424, 0.01172061, 0.03185992],\n",
       "        [0.00431177, 0.00431177, 0.08660424, 0.00431177]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Soft_3d_s_2(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Softm_Jac_1d_input(S:ndarray)->ndarray:\n",
    "    assert S.ndim == 1\n",
    "    \n",
    "    z = np.zeros([S.shape[0],S.shape[0]])   # The function computes the jacobian of the softmax function with 1d tensor input.\n",
    "    m = np.sum(exp(S))\n",
    "    n = np.power(np.sum(exp(S)),2)\n",
    "    for w in range(S.shape[0]):\n",
    "        for h in range(S.shape[0]):\n",
    "            if w==h:\n",
    "                z[w,h] = exp(S[w])*(m - exp(S[w]))/(n)\n",
    "            else:\n",
    "                z[w,h] = -exp(S[w])*exp(S[h])/(n)\n",
    "    \n",
    "    return z\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13180518, -0.09635731, -0.03544787],\n",
       "       [-0.09635731,  0.10115466, -0.00479735],\n",
       "       [-0.03544787, -0.00479735,  0.04024522]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Softm_Jac_1d_input(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Softm_Jac_2d_input(s:ndarray)->ndarray:\n",
    "    assert len(s.shape) == 2\n",
    "                                             # The function computes the jacobian of softmax function with 2d tensor input.\n",
    "    Z = np.zeros([s.shape[0],s.shape[0]])\n",
    "    M = np.sum(exp(s))                             # useful function while implementing the math. \n",
    "    N = np.power(np.sum(exp(s)),2)\n",
    "    \n",
    "    for W in range(s.shape[0]):\n",
    "        for H in range(s.shape[0]):\n",
    "            if W==H:\n",
    "                Z[W,H] = exp(s[W,0])*(M-exp(s[W,0]))/(N)\n",
    "            else:\n",
    "                Z[W,H] = -exp(s[W,0])*exp(s[H,0])/(N)\n",
    "                \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [3],\n",
       "       [2]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13180518, -0.09635731, -0.03544787],\n",
       "       [-0.09635731,  0.10115466, -0.00479735],\n",
       "       [-0.03544787, -0.00479735,  0.04024522]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Softm_Jac_2d_input(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.random.randint(2,9,size=(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 6],\n",
       "       [5, 5],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02501491, -0.00487055, -0.00024249],\n",
       "       [-0.00487055,  0.15371832, -0.00179178],\n",
       "       [-0.00024249, -0.00179178,  0.00935575]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Softm_Jac_2d_input(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Softm_data_2d(S:ndarray)->ndarray:\n",
    "    Z = np.zeros([S.shape[0],S.shape[1]])\n",
    "    \n",
    "    for w in range(S.shape[1]):\n",
    "        Z[:,w] = Softm_1d(S[:,w])              # Function to compute the sotmax function on a tensor variable(2d) corresponding\n",
    "                                                  # to a dataset.\n",
    "    return Z\n",
    "    \n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = np.random.randn(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41666785, -0.71244245, -0.42724814, -0.23171528],\n",
       "       [ 0.95470255,  0.12442508, -0.12616685, -0.58126532],\n",
       "       [ 1.24832282, -1.04006863,  1.37508615,  0.08040496]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19961056, 0.24815406, 0.11883393, 0.32559246],\n",
       "       [0.34186057, 0.57301809, 0.16058257, 0.22954439],\n",
       "       [0.45852886, 0.17882785, 0.72058349, 0.44486315]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Softm_data_2d(g1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
